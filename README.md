# ğŸ¤– AI Safety POC â€” Chatbot with Abuse & Crisis Detection

This project is a Proof-of-Concept (POC) AI chatbot designed to demonstrate real-time **abuse**, **crisis**, and **escalation** detection using NLP models. It uses:

- ğŸ§  **OpenAI GPT (chat completions)**  
- ğŸ¤— **Hugging Face Transformers for sentiment, toxicity, and hate speech detection**  
- ğŸ›ï¸ **Streamlit** for interactive UI

> âš ï¸ This project is intended for research and prototyping only. Heuristic-based crisis detection is **not suitable for production use without further validation**.

---

## ğŸ” Features

- ğŸ” Age-based **content filtering**
- ğŸš¨ Heuristic **crisis detection** (e.g., self-harm or suicidal ideation)
- ğŸ—¯ï¸ **Toxicity/abuse detection** using pre-trained models
- ğŸ“ˆ **Escalation monitoring** across conversation history
- ğŸ’¬ Chat interface with **labels**: `SAFE`, `CRISIS`, `ABUSE`, `ESCALATION`
- ğŸ§ª Debug mode to inspect underlying model predictions
- ğŸ“¤ Export chat history in JSON format

---

## ğŸ“¸ Demo

<img src="https://user-images.githubusercontent.com/your-screenshot-url" width="600" alt="AI Safety Chatbot Demo" />

---

## ğŸ› ï¸ Setup

### 1. Clone the repository

2. Install dependencies

    pip install -r requirements.txt

Add your OpenAI API key
export OPENAI_API_KEY=your-api-key

Run the App

streamlit run safety_pipeline.py
Model Details
Task	Model

Sentiment	distilbert-base-uncased-finetuned-sst-2-english
Abuse/Toxicity	unitary/toxic-bert (fallbacks to sentiment model if loading fails)
Hate Speech Filter	facebook/roberta-hate-speech-dynabench-r4-target (optional)
Chat Completion	gpt-3.5-turbo via OpenAI API

.
â”œâ”€â”€ safety_pipeline.py       # Main Streamlit app
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project description



